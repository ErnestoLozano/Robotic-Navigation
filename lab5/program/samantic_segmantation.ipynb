{"nbformat":4,"nbformat_minor":2,"metadata":{"accelerator":"GPU","colab":{"name":"lab5_Samantic_Segmentation_lab.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":["2-J1MWQfewD9","L5xIH1GffFXP","9beJVr7yfNKT"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","source":["# Semantic Segmentation with PyTorch"],"metadata":{"colab_type":"text","id":"VwfKhFfHF27m"}},{"cell_type":"markdown","source":["Mount google drive to colab."],"metadata":{"colab_type":"text","id":"qGeguvkAGNlw"}},{"cell_type":"code","execution_count":null,"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"outputs":[],"metadata":{"colab_type":"code","id":"RHc49hWDOJKw","colab":{}}},{"cell_type":"code","execution_count":null,"source":["# if you mount Google drive correctly, the following commands should be able to executed correctly\r\n","!ls /content/drive/\r\n","%cd \"/content/drive/My Drive/CamVid\"\r\n","!ls"],"outputs":[],"metadata":{"colab_type":"code","id":"eWNmktpFOddS","colab":{}}},{"cell_type":"markdown","source":["Import neccessary libraties and set parameters."],"metadata":{"colab_type":"text","id":"Jly0ouf9eNOQ"}},{"cell_type":"code","execution_count":null,"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from torchvision import models\r\n","\r\n","import numpy as np\r\n","import time\r\n","import os\r\n","\r\n","from PIL import Image\r\n","import pandas as pd"],"outputs":[],"metadata":{"colab_type":"code","id":"Qzie3tp6QThn","colab":{}}},{"cell_type":"code","execution_count":null,"source":["# dataset path\r\n","root_dir   = \"/content/drive/My Drive/CamVid/\"\r\n","train_file = os.path.join(root_dir, \"train.csv\")\r\n","val_file   = os.path.join(root_dir, \"val.csv\")\r\n","\r\n","print(\"training csv exits:{}\".format(os.path.exists(train_file)))\r\n","print(\"validation csv exits:{}\".format(os.path.exists(val_file)))\r\n","\r\n","# Create folder to store training results.\r\n","val_dir = \"/content/drive/My Drive/segmentation_output/\"\r\n","if os.path.isdir(val_dir) == False:\r\n","   os.mkdir(val_dir)\r\n","\r\n","# Parameters\r\n","num_class = 11 # 32 for original CamVid\r\n","input_h, input_w = 256, 256\r\n","batch_size = 16\r\n","epochs = 40\r\n","lr = 1e-4\r\n","use_gpu = torch.cuda.is_available()\r\n","\r\n","# index for validation images\r\n","global_index = 0\r\n","\r\n","# pixel accuracy and mIOU list \r\n","pixel_acc_list = []\r\n","mIOU_list = []"],"outputs":[],"metadata":{"colab_type":"code","id":"hyGTWuMwngPV","colab":{}}},{"cell_type":"markdown","source":["## CamVid Dataset"],"metadata":{"colab_type":"text","id":"nphF6DjpeZVB"}},{"cell_type":"code","execution_count":null,"source":["class CamVidDataset(Dataset):\r\n","    def __init__(self, csv_file, n_class=num_class, flip_rate=0.5, rand_crop=True):\r\n","        self.data = pd.read_csv(csv_file)\r\n","        self.n_class = n_class\r\n","        self.new_h = input_h\r\n","        self.new_w = input_w\r\n","        self.flip_rate = flip_rate  \r\n","        self.rand_crop = rand_crop\r\n","\r\n","    def __len__(self):\r\n","        return len(self.data)\r\n","\r\n","    def __getitem__(self, idx):\r\n","        # open image data\r\n","        img_name   = self.data.iloc[idx, 0]                \r\n","        img_name = root_dir  + img_name                        \r\n","        img = Image.open(img_name).convert('RGB')\r\n","        \r\n","        # open label data\r\n","        label_name = self.data.iloc[idx, 1]        \r\n","        label_name = root_dir  + label_name                       \r\n","        label_image = Image.open(label_name)\r\n","        \r\n","        # crop images and labels\r\n","        w, h = img.size\r\n","        if self.rand_crop:            \r\n","            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\r\n","            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\r\n","        else:            \r\n","            A_x_offset = int((w - self.new_w)/2)\r\n","            A_y_offset = int((h - self.new_h)/2)\r\n","       \r\n","        img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\r\n","        label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\r\n","\r\n","        # flip images and labels\r\n","        img = np.transpose(img, (2, 0, 1)) / 255.\r\n","        label = np.asarray(label_image)\r\n","        if np.random.sample() < self.flip_rate:\r\n","            img = np.fliplr(img)\r\n","            label = np.fliplr(label)\r\n","\r\n","        # create tensor\r\n","        img = torch.from_numpy(img.copy()).float()\r\n","        label = torch.from_numpy(label.copy()).long()\r\n","\r\n","        # create one-hot encoding tensor\r\n","        h, w = label.size()\r\n","        target = torch.zeros(self.n_class, h, w)\r\n","        for c in range(self.n_class):\r\n","            target[c][label == c] = 1\r\n","\r\n","        sample = {'X': img, 'Y': target, 'l': label}\r\n","        return sample\r\n","\r\n","# Load dataset\r\n","train_data = CamVidDataset(csv_file=train_file, flip_rate=0.5, rand_crop=True)\r\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\r\n","val_data = CamVidDataset(csv_file=val_file, flip_rate=0, rand_crop=False)\r\n","val_loader = DataLoader(val_data, batch_size=1, num_workers=8)"],"outputs":[],"metadata":{"colab_type":"code","id":"HEgjfY74izJR","colab":{}}},{"cell_type":"markdown","source":["## Network Model\n","### VGG16 Feature Extractor (pretrained)"],"metadata":{"colab_type":"text","id":"rKvpt9GTefaL"}},{"cell_type":"code","execution_count":null,"source":["class Vgg16(nn.Module):\r\n","    def __init__(self, pretrained = True):\r\n","        super(Vgg16, self).__init__()\r\n","        self.vggnet = models.vgg16(pretrained)\r\n","        del(self.vggnet.classifier) # Remove fully connected layer to save memory.\r\n","        features = list(self.vggnet.features)\r\n","        self.layers = nn.ModuleList(features).eval() \r\n","        \r\n","    def forward(self, x):\r\n","        results = []\r\n","        for ii,model in enumerate(self.layers):\r\n","            x = model(x)\r\n","            if ii in [3,8,15,22,29]:\r\n","                results.append(x) #(64,256,256),(128,128,128),(256,64,64),(512,32,32),(512,16,16)\r\n","        return results\r\n","\r\n","vgg_model = Vgg16()\r\n","vgg_model = vgg_model.cuda()\r\n","print(vgg_model.layers)"],"outputs":[],"metadata":{"colab_type":"code","id":"CUfJoO8e-rrB","colab":{}}},{"cell_type":"markdown","source":["### Encoder-Decoder"],"metadata":{"colab_type":"text","id":"10fl6vwtE2Dz"}},{"cell_type":"code","execution_count":null,"source":["class DeConv2d(nn.Module):\r\n","    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, dilation):\r\n","        super().__init__()\r\n","        self.up = nn.Upsample(scale_factor=2, mode='nearest')\r\n","        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation)\r\n","\r\n","    def forward(self, x):\r\n","        output = self.up(x)\r\n","        output = self.conv(output)\r\n","        return output\r\n","\r\n","class EncoderDecoder(nn.Module):\r\n","    def __init__(self, pretrained_net, n_class):\r\n","        super().__init__()\r\n","        self.n_class = n_class\r\n","        self.pretrained_net = pretrained_net\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","\r\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn1 = nn.BatchNorm2d(512)\r\n","        \r\n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn2 = nn.BatchNorm2d(256)\r\n","        \r\n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn3 = nn.BatchNorm2d(128)\r\n","        \r\n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn4 = nn.BatchNorm2d(64)\r\n","        \r\n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\r\n","\r\n","    def forward(self, x):\r\n","        output = self.pretrained_net(x)[4]\r\n","        output = self.bn1(self.relu(self.deconv1(output)))\r\n","        output = self.bn2(self.relu(self.deconv2(output)))\r\n","        output = self.bn3(self.relu(self.deconv3(output)))\r\n","        output = self.bn4(self.relu(self.deconv4(output)))\r\n","        output = self.classifier(output)\r\n","        return output"],"outputs":[],"metadata":{"colab_type":"code","id":"CVmJVvvj1W9H","colab":{}}},{"cell_type":"markdown","source":["### Fully Convolution Network (FCN)\n"],"metadata":{"colab_type":"text","id":"2-J1MWQfewD9"}},{"cell_type":"code","execution_count":null,"source":["class FCN(nn.Module):\r\n","    def __init__(self, pretrained_net, n_class):\r\n","        super().__init__()\r\n","        self.n_class = n_class\r\n","        self.pretrained_net = pretrained_net\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","\r\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn1 = nn.BatchNorm2d(512)\r\n","        \r\n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn2 = nn.BatchNorm2d(256)\r\n","        \r\n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn3 = nn.BatchNorm2d(128)\r\n","        \r\n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn4 = nn.BatchNorm2d(64)\r\n","        \r\n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\r\n","\r\n","    def forward(self, x):\r\n","        output = self.pretrained_net(x)\r\n","        x0, x1, x2, x3, x4 = output\r\n","\r\n","        output = self.bn1(self.relu(self.deconv1(x4)))\r\n","        output += x3\r\n","        output = self.bn2(self.relu(self.deconv2(output)))\r\n","        output += x2\r\n","        output = self.bn3(self.relu(self.deconv3(output)))\r\n","        output += x1\r\n","        output = self.bn4(self.relu(self.deconv4(output)))\r\n","        output += x0\r\n","        output = self.classifier(output)\r\n","        return output"],"outputs":[],"metadata":{"colab_type":"code","id":"MjZ4-8X1EzFv","colab":{}}},{"cell_type":"markdown","source":["### U-Net"],"metadata":{"colab_type":"text","id":"L5xIH1GffFXP"}},{"cell_type":"code","execution_count":null,"source":["class UNet(nn.Module):\r\n","    def __init__(self, pretrained_net, n_class):\r\n","        super().__init__()\r\n","        self.n_class = n_class\r\n","        self.pretrained_net = pretrained_net\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","\r\n","        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn1 = nn.BatchNorm2d(512)\r\n","        \r\n","        self.deconv2 = DeConv2d(512*2, 256, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn2 = nn.BatchNorm2d(256)\r\n","        \r\n","        self.deconv3 = DeConv2d(256*2, 128, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn3 = nn.BatchNorm2d(128)\r\n","        \r\n","        self.deconv4 = DeConv2d(128*2, 64, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn4 = nn.BatchNorm2d(64)\r\n","        \r\n","        self.classifier = nn.Conv2d(64*2, n_class, kernel_size=1)\r\n","    \r\n","    def forward(self, x):\r\n","        output = self.pretrained_net(x)\r\n","        x0, x1, x2, x3, x4 = output\r\n","\r\n","        output = self.bn1(self.relu(self.deconv1(x4)))\r\n","        output = torch.cat([output, x3], dim=1)\r\n","        output = self.bn2(self.relu(self.deconv2(output)))\r\n","        output = torch.cat([output, x2], dim=1)\r\n","        output = self.bn3(self.relu(self.deconv3(output)))\r\n","        output = torch.cat([output, x1], dim=1)\r\n","        output = self.bn4(self.relu(self.deconv4(output)))\r\n","        output = torch.cat([output, x0], dim=1)\r\n","        output = self.classifier(output)\r\n","        return output"],"outputs":[],"metadata":{"colab_type":"code","id":"ZbAKDtkwJQH7","colab":{}}},{"cell_type":"markdown","source":["### PSPNet"],"metadata":{"colab_type":"text","id":"mwISqBr0yMTQ"}},{"cell_type":"code","execution_count":null,"source":["class PPM(nn.Module):\r\n","    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, dilation):\r\n","        super().__init__()\r\n","        # Pyramid Pooling Moudule\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.ppm_size = (16,16)\r\n","        self.ppm_channel = 512\r\n","        self.ppm_psize = [1,2,3,6]\r\n","        self.ppm_pool, self.ppm_conv, self.ppm_up = [], [], []\r\n","\r\n","        for psize in self.ppm_psize:\r\n","            self.ppm_pool.append(nn.AdaptiveAvgPool2d((psize,psize)))\r\n","            self.ppm_conv.append(nn.Conv2d(int(self.ppm_channel), int(self.ppm_channel/len(self.ppm_psize)), kernel_size=1))\r\n","            self.ppm_up.append(nn.Upsample(size=self.ppm_size, mode='bilinear', align_corners=True))\r\n","\r\n","        self.ppm_pool = nn.ModuleList(self.ppm_pool)\r\n","        self.ppm_conv = nn.ModuleList(self.ppm_conv)\r\n","        self.ppm_up = nn.ModuleList(self.ppm_up)\r\n","\r\n","    def forward(self, x):\r\n","        ppm_list = [x]\r\n","        for i in range(len(self.ppm_psize)):\r\n","            output = self.ppm_pool[i](x)\r\n","            output = self.ppm_conv[i](output)\r\n","            output = self.ppm_up[i](self.relu(output))\r\n","            ppm_list.append(output)\r\n","            output = torch.cat(ppm_list, 1)\r\n","        return output\r\n","\r\n","class PSPNet(nn.Module):\r\n","    def __init__(self, pretrained_net, n_class):\r\n","        super().__init__()\r\n","        self.n_class = n_class\r\n","        self.pretrained_net = pretrained_net\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","\r\n","        self.ppm = PPM(512, 1024, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","\r\n","        self.deconv1 = DeConv2d(1024, 512, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn1 = nn.BatchNorm2d(512)\r\n","        \r\n","        self.deconv2 = DeConv2d(512, 256, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn2 = nn.BatchNorm2d(256)\r\n","        \r\n","        self.deconv3 = DeConv2d(256, 128, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn3 = nn.BatchNorm2d(128)\r\n","        \r\n","        self.deconv4 = DeConv2d(128, 64, kernel_size=3, stride=1, padding=1, dilation=1)\r\n","        self.bn4 = nn.BatchNorm2d(64)\r\n","        \r\n","        self.classifier = nn.Conv2d(64, n_class, kernel_size=1)\r\n","\r\n","    def forward(self, x):\r\n","        output = self.pretrained_net(x)\r\n","        x0, x1, x2, x3, x4 = output\r\n","\r\n","        output = self.ppm(x4)\r\n","        output = self.bn1(self.relu(self.deconv1(output)))\r\n","        output += x3\r\n","        output = self.bn2(self.relu(self.deconv2(output)))\r\n","        output += x2\r\n","        output = self.bn3(self.relu(self.deconv3(output)))\r\n","        output += x1\r\n","        output = self.bn4(self.relu(self.deconv4(output)))\r\n","        output += x0\r\n","        output = self.classifier(output)\r\n","        return output"],"outputs":[],"metadata":{"colab_type":"code","id":"ttK5Y9AuyJ7y","colab":{}}},{"cell_type":"markdown","source":["# Construct models."],"metadata":{"colab_type":"text","id":"xjcje1cPfIYs"}},{"cell_type":"code","execution_count":null,"source":["# seg_model = EncoderDecoder(pretrained_net=vgg_model, n_class=num_class)\r\n","# seg_model = FCN(pretrained_net=vgg_model, n_class=num_class)\r\n","# seg_model = UNet(pretrained_net=vgg_model, n_class=num_class)\r\n","seg_model = PSPNet(pretrained_net=vgg_model, n_class=num_class)\r\n","\r\n","seg_model = seg_model.cuda()\r\n","criterion = nn.BCEWithLogitsLoss()\r\n","optimizer = optim.Adam(seg_model.parameters(), lr=lr)"],"outputs":[],"metadata":{"colab_type":"code","id":"oj3Ng3mi1deU","colab":{}}},{"cell_type":"markdown","source":["# Training and Validation"],"metadata":{"colab_type":"text","id":"9beJVr7yfNKT"}},{"cell_type":"code","execution_count":null,"source":["def train():\r\n","    for epoch in range(epochs):\r\n","        ts = time.time()\r\n","        for iter, batch in enumerate(train_loader):\r\n","            optimizer.zero_grad()\r\n","            inputs = torch.FloatTensor(batch['X'])\r\n","            labels = torch.FloatTensor(batch['Y'])\r\n","            if use_gpu:\r\n","              inputs = inputs.cuda()\r\n","              labels = labels.cuda()\r\n","\r\n","            outputs = seg_model(inputs)\r\n","            loss = criterion(outputs, labels)\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","\r\n","            if iter % 10 == 0:\r\n","                print(\"epoch:{:2}, iter:{:2}, loss: {:.4f}\".format(epoch, iter, loss.data.item()))\r\n","        \r\n","        print(\"Finish epoch:{:2}, time elapsed: {:.4f}\".format(epoch, time.time() - ts))\r\n","        validate()\r\n","        print(\"========================================\")\r\n","        \r\n","    highest_pixel_acc = max(pixel_acc_list)\r\n","    highest_mIOU = max(mIOU_list)        \r\n","    \r\n","    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\r\n","    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\r\n","    \r\n","    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\r\n","    print(\"The highest pixel accuracy  is {} and is achieved at epoch-{}\".format(highest_pixel_acc, highest_pixel_acc_epoch))"],"outputs":[],"metadata":{"colab_type":"code","id":"pQtApd8vLCa8","colab":{}}},{"cell_type":"code","execution_count":null,"source":["def validate():\r\n","    seg_model.eval()\r\n","    total_ious = []\r\n","    pixel_accs = []\r\n","                    \r\n","    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\r\n","        inputs = torch.FloatTensor(batch['X'])\r\n","        if use_gpu:\r\n","          inputs = inputs.cuda()      \r\n","\r\n","        output = seg_model(inputs)                                \r\n","        \r\n","        # only save the 1st image for comparison\r\n","        if iter == 0:\r\n","            # generate images\r\n","            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\r\n","            image = images[0,:,:]        \r\n","            save_result(batch['X'], image)\r\n","                            \r\n","        output = output.data.cpu().numpy()\r\n","\r\n","        N, _, h, w = output.shape                \r\n","        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \r\n","        target = batch['l'].cpu().numpy().reshape(N, h, w)\r\n","\r\n","        for p, t in zip(pred, target):\r\n","            total_ious.append(iou(p, t))\r\n","            pixel_accs.append(pixel_acc(p, t))\r\n","\r\n","    # Calculate average IoU\r\n","    total_ious = np.array(total_ious).T  # n_class * val_len\r\n","    ious = np.nanmean(total_ious, axis=1)\r\n","    pixel_accs = np.array(pixel_accs).mean()\r\n","    print(\"pix_acc: {:.4f}, meanIoU: {:.4f}\".format(pixel_accs, np.nanmean(ious)))\r\n","    \r\n","    global pixel_acc_list\r\n","    global mIOU_list\r\n","    \r\n","    pixel_acc_list.append(pixel_accs)\r\n","    mIOU_list.append(np.nanmean(ious))\r\n","\r\n","# Calculates class intersections over unions\r\n","def iou(pred, target):\r\n","    ious = []\r\n","    for cls in range(num_class):\r\n","        pred_inds = pred == cls\r\n","        target_inds = target == cls\r\n","        intersection = pred_inds[target_inds].sum()\r\n","        union = pred_inds.sum() + target_inds.sum() - intersection\r\n","        if union == 0:\r\n","            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\r\n","        else:\r\n","            ious.append(float(intersection) / max(union, 1))\r\n","    return ious\r\n","\r\n","def pixel_acc(pred, target):\r\n","    correct = (pred == target).sum()\r\n","    total   = (target == target).sum()\r\n","    return correct / total     \r\n","\r\n","def save_result(input_np, output_np):\r\n","    global global_index\r\n","    \r\n","    original_im_RGB = np.zeros((256,256,3))    \r\n","    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \r\n","    original_im_RGB[:,:,1] = input_np[0,1,:,:]\r\n","    original_im_RGB[:,:,2] = input_np[0,2,:,:]\r\n","        \r\n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] \r\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] \r\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] \r\n","        \r\n","    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\r\n","    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\r\n","    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\r\n","    \r\n","    im_seg_RGB = np.zeros((256,256,3))\r\n","\r\n","    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\r\n","    for i in range(256):\r\n","        for j in range(256):\r\n","            if output_np[i,j] == 0:\r\n","                im_seg_RGB[i,j,:] = [128, 128, 128]\r\n","            elif output_np[i,j] == 1:  \r\n","                im_seg_RGB[i,j,:] = [128, 0, 0]\r\n","            elif output_np[i,j] == 2:  \r\n","                im_seg_RGB[i,j,:] = [192, 192, 128]    \r\n","            elif output_np[i,j] == 3:  \r\n","                im_seg_RGB[i,j,:] = [128, 64, 128]    \r\n","            elif output_np[i,j] == 4:  \r\n","                im_seg_RGB[i,j,:] = [0, 0, 192]    \r\n","            elif output_np[i,j] == 5:  \r\n","                im_seg_RGB[i,j,:] = [128, 128, 0]    \r\n","            elif output_np[i,j] == 6:  \r\n","                im_seg_RGB[i,j,:] = [192, 128, 128]    \r\n","            elif output_np[i,j] == 7:  \r\n","                im_seg_RGB[i,j,:] = [64, 64, 128]    \r\n","            elif output_np[i,j] == 8:  \r\n","                im_seg_RGB[i,j,:] = [64, 0, 128]    \r\n","            elif output_np[i,j] == 9:  \r\n","                im_seg_RGB[i,j,:] = [64, 64, 0]    \r\n","            elif output_np[i,j] == 10:  \r\n","                im_seg_RGB[i,j,:] = [0, 128, 192]    \r\n","                    \r\n","    # horizontally stack original image and its corresponding segmentation results     \r\n","    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \r\n","    new_im = Image.fromarray(np.uint8(hstack_image))\r\n","    file_name = val_dir + str(global_index).zfill(3) + '.jpg'\r\n","    global_index = global_index + 1\r\n","    new_im.save(file_name)  "],"outputs":[],"metadata":{"colab_type":"code","id":"DtvW9ZqJnmLE","colab":{}}},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"W3SisOV9XHy8","colab_type":"text"}},{"cell_type":"code","execution_count":null,"source":["# perform training and validation\r\n","train()"],"outputs":[],"metadata":{"id":"5AeqYVufXI65","colab_type":"code","colab":{}}}]}